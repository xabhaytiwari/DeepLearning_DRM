{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wy751dU9Fya0",
        "outputId": "c7cad17f-2e26-48be-b9c6-84aaffc724e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Cell 1: Setup and Imports\n",
        "# =========================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "torch.set_default_dtype(torch.float64)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fzv8EdQyF0eo",
        "outputId": "9e00236d-1f33-4c24-a146-3d722b9d6701"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=2, out_features=100, bias=True)\n",
              "    (1): Tanh()\n",
              "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
              "    (3): Tanh()\n",
              "    (4): Linear(in_features=100, out_features=100, bias=True)\n",
              "    (5): Tanh()\n",
              "    (6): Linear(in_features=100, out_features=100, bias=True)\n",
              "    (7): Tanh()\n",
              "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# =========================\n",
        "# Cell 2: Network Definition\n",
        "# =========================\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(2, 100), nn.Tanh(),\n",
        "            nn.Linear(100, 100), nn.Tanh(),\n",
        "            nn.Linear(100, 100), nn.Tanh(),\n",
        "            nn.Linear(100, 100), nn.Tanh(),\n",
        "            nn.Linear(100, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "model = Net().to(device)\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        nn.init.zeros_(m.bias)\n",
        "model.apply(init_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pfJzlNfTF0bz"
      },
      "outputs": [],
      "source": [
        "# =============================\n",
        "# Cell 3: Exact Solution & RHS\n",
        "# =============================\n",
        "def exact_solution(x):\n",
        "    return (1/(2*np.pi**2)) * torch.sin(np.pi*x[:,0]) * torch.sin(np.pi*x[:,1])\n",
        "\n",
        "def rhs_f(x):\n",
        "    return (np.pi**4 / 2) * torch.sin(np.pi*x[:,0]) * torch.sin(np.pi*x[:,1])\n",
        "\n",
        "def dirichlet_bc(x):\n",
        "    return exact_solution(x)\n",
        "\n",
        "def neumann_bc(x, n):\n",
        "    # u_exact = (1/2pi^2) * sin(pi*x) * sin(pi*y)\n",
        "    # du/dx = (1/2pi) * cos(pi*x) * sin(pi*y)\n",
        "    # du/dy = (1/2pi) * sin(pi*x) * cos(pi*y)\n",
        "    \n",
        "    du_dx = (1/(2*np.pi)) * torch.cos(np.pi*x[:,0]) * torch.sin(np.pi*x[:,1])\n",
        "    du_dy = (1/(2*np.pi)) * torch.sin(np.pi*x[:,0]) * torch.cos(np.pi*x[:,1])\n",
        "    \n",
        "    # Normal derivative = dot product of gradient and normal\n",
        "    # n has shape (N, 2), du_dx/dy have shape (N,)\n",
        "    du_dn = du_dx * n[:,0] + du_dy * n[:,1]\n",
        "    return du_dn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gPW9VaplF0Z0"
      },
      "outputs": [],
      "source": [
        "# ==============================================\n",
        "# Cell 4: Collocation and Boundary Point Sampler\n",
        "# ==============================================\n",
        "N_int, N_bd = 8000, 4000\n",
        "def get_interior(N):\n",
        "    return torch.rand(N, 2, device=device)\n",
        "\n",
        "def get_boundary(M):\n",
        "    grid = torch.linspace(0, 1, M//4, device=device)\n",
        "    zeros = torch.zeros_like(grid)\n",
        "    ones = torch.ones_like(grid)\n",
        "    \n",
        "    # Points\n",
        "    pts = [\n",
        "        torch.stack([grid, zeros], dim=1), # Bottom\n",
        "        torch.stack([grid, ones], dim=1),  # Top\n",
        "        torch.stack([zeros, grid], dim=1), # Left\n",
        "        torch.stack([ones, grid], dim=1)   # Right\n",
        "    ]\n",
        "    \n",
        "    # Normal vectors corresponding to the points\n",
        "    normals = [\n",
        "        torch.stack([zeros, -ones], dim=1), # Bottom normal (0, -1)\n",
        "        torch.stack([zeros, ones], dim=1),  # Top normal (0, 1)\n",
        "        torch.stack([-ones, zeros], dim=1), # Left normal (-1, 0)\n",
        "        torch.stack([ones, zeros], dim=1)   # Right normal (1, 0)\n",
        "    ]\n",
        "    \n",
        "    return torch.cat(pts, dim=0), torch.cat(normals, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ULddWXhVF0Xr"
      },
      "outputs": [],
      "source": [
        "# =================================\n",
        "# Cell 5: Improved Loss Functional\n",
        "# =================================\n",
        "def biharmonic_loss(model, x_int, x_bd, n_bd, bc_weight=10000.0):\n",
        "    # --- 1. Interior Loss (Same as before) ---\n",
        "    x_int.requires_grad_()\n",
        "    u = model(x_int)\n",
        "\n",
        "    grad_u = torch.autograd.grad(u, x_int, grad_outputs=torch.ones_like(u),\n",
        "                                create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    lap_u = torch.zeros_like(u.squeeze())\n",
        "    for i in range(2):\n",
        "        grad_ui = torch.autograd.grad(grad_u[:, i], x_int,\n",
        "                                     grad_outputs=torch.ones_like(grad_u[:, i]),\n",
        "                                     create_graph=True, retain_graph=True)[0][:, i]\n",
        "        lap_u += grad_ui\n",
        "\n",
        "    grad_lap = torch.autograd.grad(lap_u, x_int,\n",
        "                                  grad_outputs=torch.ones_like(lap_u),\n",
        "                                  create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "    biharmonic = torch.zeros_like(lap_u)\n",
        "    for i in range(2):\n",
        "        biharmonic += torch.autograd.grad(grad_lap[:, i], x_int,\n",
        "                                        grad_outputs=torch.ones_like(grad_lap[:, i]),\n",
        "                                        create_graph=True)[0][:, i]\n",
        "\n",
        "    f = rhs_f(x_int)\n",
        "    pde_loss = ((biharmonic - f)**2).mean()\n",
        "\n",
        "    # --- 2. Dirichlet Boundary Loss (u = g1) ---\n",
        "    # Important: Enable gradients for boundary points too!\n",
        "    x_bd.requires_grad_() \n",
        "    u_bd = model(x_bd)\n",
        "    bc1_loss = ((u_bd.squeeze() - dirichlet_bc(x_bd))**2).mean()\n",
        "    \n",
        "    # --- 3. Neumann Boundary Loss (du/dn = g2) ---\n",
        "    # Calculate gradient at boundary\n",
        "    grad_u_bd = torch.autograd.grad(u_bd, x_bd, grad_outputs=torch.ones_like(u_bd),\n",
        "                                   create_graph=True, retain_graph=True)[0]\n",
        "    \n",
        "    # Calculate normal derivative: (grad_u . n)\n",
        "    du_dn_pred = grad_u_bd[:, 0] * n_bd[:, 0] + grad_u_bd[:, 1] * n_bd[:, 1]\n",
        "    \n",
        "    # Calculate target\n",
        "    du_dn_target = neumann_bc(x_bd, n_bd)\n",
        "    \n",
        "    bc2_loss = ((du_dn_pred - du_dn_target)**2).mean()\n",
        "\n",
        "    # Combine losses\n",
        "    total_loss = pde_loss + bc_weight * (bc1_loss + bc2_loss)\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyK4SEK-F0Vq",
        "outputId": "331633d4-df54-41bb-f445-4b895f2e1c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n"
          ]
        }
      ],
      "source": [
        "# =============================\n",
        "# Cell 6: Training Configuration\n",
        "# =============================\n",
        "epochs = 10000\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                      factor=0.5, patience=500)\n",
        "losses = []\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    x_int, (x_bd, n_bd) = get_interior(N_int), get_boundary(N_bd)\n",
        "    loss = biharmonic_loss(model, x_int, x_bd, n_bd, bc_weight=10000.0)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step(loss)\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss {loss.item():.6e}, LR: {scheduler.optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "# Final LBFGS optimization\n",
        "print(\"Starting LBFGS fine-tuning...\")\n",
        "lbfgs_optimizer = torch.optim.LBFGS(model.parameters(), lr=0.1, max_iter=1000,\n",
        "                                   tolerance_grad=1e-8, tolerance_change=1e-10,\n",
        "                                   history_size=100)\n",
        "\n",
        "def closure():\n",
        "    lbfgs_optimizer.zero_grad()\n",
        "    x_int, x_bd = get_interior(N_int), get_boundary(N_bd)\n",
        "    loss = biharmonic_loss(model, x_int, x_bd, bc_weight=10000.0)\n",
        "    loss.backward()\n",
        "    return loss\n",
        "\n",
        "lbfgs_optimizer.step(closure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCR2aegUF0Tx"
      },
      "outputs": [],
      "source": [
        "# ===================\n",
        "# Cell 7: Save Output\n",
        "# ===================\n",
        "torch.save(model.state_dict(), \"improved_biharmonic_model_q1.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P35x7nQ1F0R3",
        "outputId": "38dc90aa-ae7e-4eb0-9007-f25656ff0a6d"
      },
      "outputs": [],
      "source": [
        "# =============================\n",
        "# Cell 8: Print Architecture, Stats\n",
        "# =============================\n",
        "train_time = time.time() - start_time\n",
        "print(f\"\\n=== TRAINING SUMMARY ===\")\n",
        "print(f\"Training time: {train_time:.2f} seconds\")\n",
        "print(\"Neural Network Architecture:\")\n",
        "print(model)\n",
        "n_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total parameters: {n_params}\")\n",
        "print(f\"Non-zero parameters: {sum(torch.count_nonzero(p).item() for p in model.parameters())}\")\n",
        "print(f\"Adam initial lr: 1e-3, LBFGS steps: 1000\")\n",
        "print(f\"Interior points: {N_int}, Boundary points: {N_bd}\")\n",
        "print(f\"Boundary penalty weight: {10000.0}\")\n",
        "print(f\"Final training loss: {losses[-1]:.6e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "oOjd6U_0F0P4",
        "outputId": "ec5ddd8c-f7b2-40d4-9a09-85892fa8e602"
      },
      "outputs": [],
      "source": [
        "# ===================================\n",
        "# Cell 9: Plot Solutions and Error\n",
        "# ===================================\n",
        "print(\"\\nGenerating plots...\")\n",
        "gsize = 61\n",
        "xg = np.linspace(0, 1, gsize)\n",
        "X, Y = np.meshgrid(xg, xg)\n",
        "grid_points = torch.tensor(np.stack([X.ravel(), Y.ravel()], axis=-1),\n",
        "                          device=device, dtype=torch.float64)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    u_nn = model(grid_points).cpu().numpy().reshape(gsize, gsize)\n",
        "    u_gt = exact_solution(grid_points).cpu().numpy().reshape(gsize, gsize)\n",
        "    err = np.abs(u_nn - u_gt)\n",
        "\n",
        "# Neural Network Solution\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.contourf(X, Y, u_nn, levels=50, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.title('Neural Network Solution')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "\n",
        "# Exact Solution\n",
        "plt.subplot(132)\n",
        "plt.contourf(X, Y, u_gt, levels=50, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.title('Exact Solution')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "\n",
        "# Absolute Error\n",
        "plt.subplot(133)\n",
        "err_plot = plt.contourf(X, Y, err, levels=50, cmap='hot')\n",
        "plt.colorbar(err_plot)\n",
        "plt.title('Absolute Error')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"solutions_comparison_q1.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# 3D Plots\n",
        "fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "ax1 = fig.add_subplot(131, projection='3d')\n",
        "ax1.plot_surface(X, Y, u_nn, cmap='jet', alpha=0.8)\n",
        "ax1.set_title('NN Solution (3D)')\n",
        "ax1.set_xlabel('x')\n",
        "ax1.set_ylabel('y')\n",
        "ax1.set_zlabel('u(x,y)')\n",
        "\n",
        "ax2 = fig.add_subplot(132, projection='3d')\n",
        "ax2.plot_surface(X, Y, u_gt, cmap='jet', alpha=0.8)\n",
        "ax2.set_title('Exact Solution (3D)')\n",
        "ax2.set_xlabel('x')\n",
        "ax2.set_ylabel('y')\n",
        "ax2.set_zlabel('u(x,y)')\n",
        "\n",
        "ax3 = fig.add_subplot(133, projection='3d')\n",
        "ax3.plot_surface(X, Y, err, cmap='hot', alpha=0.8)\n",
        "ax3.set_title('Absolute Error (3D)')\n",
        "ax3.set_xlabel('x')\n",
        "ax3.set_ylabel('y')\n",
        "ax3.set_zlabel('Error')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"3d_solutions_q1.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyZjHuAZF0N7",
        "outputId": "f1448566-81aa-4958-979a-1c02d3e70a15"
      },
      "outputs": [],
      "source": [
        "# ==================================\n",
        "# Cell 10: Error Metrics Calculation\n",
        "# ==================================\n",
        "print(\"\\nComputing error metrics...\")\n",
        "grid_points.requires_grad = True\n",
        "\n",
        "# Compute solutions and gradients\n",
        "u_gt_val = exact_solution(grid_points)\n",
        "u_nn_val = model(grid_points)\n",
        "\n",
        "# First derivatives\n",
        "u_gt_grad = torch.autograd.grad(u_gt_val, grid_points, torch.ones_like(u_gt_val),\n",
        "                               create_graph=True)[0]\n",
        "u_nn_grad = torch.autograd.grad(u_nn_val, grid_points, torch.ones_like(u_nn_val),\n",
        "                               create_graph=True)[0]\n",
        "\n",
        "# Second derivatives\n",
        "H_gt = []\n",
        "H_nn = []\n",
        "for i in range(2):\n",
        "    H_gt_i = torch.autograd.grad(u_gt_grad[:, i], grid_points,\n",
        "                                torch.ones_like(u_gt_grad[:, i]),\n",
        "                                create_graph=True)[0][:, i]\n",
        "    H_nn_i = torch.autograd.grad(u_nn_grad[:, i], grid_points,\n",
        "                                torch.ones_like(u_nn_grad[:, i]),\n",
        "                                create_graph=True)[0][:, i]\n",
        "    H_gt.append(H_gt_i.detach().cpu().numpy())\n",
        "    H_nn.append(H_nn_i.detach().cpu().numpy())\n",
        "\n",
        "# Convert to numpy for error computation\n",
        "u_gt_np = u_gt_val.detach().cpu().numpy().ravel()\n",
        "u_nn_np = u_nn_val.detach().cpu().numpy().ravel()\n",
        "u_gt_grad_np = u_gt_grad.detach().cpu().numpy()\n",
        "u_nn_grad_np = u_nn_grad.detach().cpu().numpy()\n",
        "\n",
        "# Error computation functions\n",
        "def L2_norm(u):\n",
        "    return np.sqrt(np.mean(u**2))\n",
        "\n",
        "def H1_norm(u, grad):\n",
        "    return np.sqrt(np.mean(u**2) + np.mean(grad[:,0]**2 + grad[:,1]**2))\n",
        "\n",
        "def H2_norm(u, grad, H):\n",
        "    return np.sqrt(np.mean(u**2) + np.mean(grad[:,0]**2 + grad[:,1]**2) +\n",
        "                  np.mean(H[0]**2 + H[1]**2))\n",
        "\n",
        "# Compute errors\n",
        "L2_err = L2_norm(u_gt_np - u_nn_np)\n",
        "H1_err = H1_norm(u_gt_np - u_nn_np, u_gt_grad_np - u_nn_grad_np)\n",
        "H2_err = H2_norm(u_gt_np - u_nn_np, u_gt_grad_np - u_nn_grad_np,\n",
        "                [H_gt[0]-H_nn[0], H_gt[1]-H_nn[1]])\n",
        "\n",
        "# Relative errors\n",
        "L2_norm_gt = L2_norm(u_gt_np)\n",
        "H1_norm_gt = H1_norm(u_gt_np, u_gt_grad_np)\n",
        "H2_norm_gt = H2_norm(u_gt_np, u_gt_grad_np, H_gt)\n",
        "\n",
        "rel_L2_err = L2_err / L2_norm_gt\n",
        "rel_H1_err = H1_err / H1_norm_gt\n",
        "rel_H2_err = H2_err / H2_norm_gt\n",
        "\n",
        "print(\"\\n=== ERROR METRICS ===\")\n",
        "print(f\"L2 Error: {L2_err:.3e}\")\n",
        "print(f\"Relative L2 Error: {rel_L2_err:.3e}\")\n",
        "print(f\"H1 Error: {H1_err:.3e}\")\n",
        "print(f\"Relative H1 Error: {rel_H1_err:.3e}\")\n",
        "print(f\"H2 Error: {H2_err:.3e}\")\n",
        "print(f\"Relative H2 Error: {rel_H2_err:.3e}\")\n",
        "\n",
        "# Check if requirements are met\n",
        "print(\"\\n=== REQUIREMENTS CHECK ===\")\n",
        "print(f\"Final loss ~1e-5: {'✓' if losses[-1] < 1e-4 else '✗'} (Current: {losses[-1]:.2e})\")\n",
        "print(f\"L2 error ~1e-3: {'✓' if L2_err < 2e-3 else '✗'} (Current: {L2_err:.2e})\")\n",
        "print(f\"H1 error ~1e-3: {'✓' if H1_err < 2e-3 else '✗'} (Current: {H1_err:.2e})\")\n",
        "print(f\"H2 error ~1e-3: {'✓' if H2_err < 2e-3 else '✗'} (Current: {H2_err:.2e})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "q6XPC2RRF0L4",
        "outputId": "52b8d44d-655c-4046-9577-914d05f79dc6"
      },
      "outputs": [],
      "source": [
        "# ===================================\n",
        "# Cell 11: Plot Loss History\n",
        "# ===================================\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogy(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss History (Log Scale)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.savefig(\"loss_history_q1.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Save loss history\n",
        "with open(\"loss_history_q1.pkl\", \"wb\") as f:\n",
        "    pickle.dump(losses, f)\n",
        "\n",
        "print(f\"\\nResults saved:\")\n",
        "print(\"- improved_biharmonic_model.pt: Trained model weights\")\n",
        "print(\"- solutions_comparison.png: 2D comparison plot\")\n",
        "print(\"- 3d_solutions.png: 3D surface plots\")\n",
        "print(\"- loss_history.png: Training dynamics\")\n",
        "print(\"- loss_history.pkl: Loss history data\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
